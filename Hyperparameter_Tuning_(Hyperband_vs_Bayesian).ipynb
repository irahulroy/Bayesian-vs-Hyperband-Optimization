{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter Tuning (Hyperband vs Bayesian).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SQv7chzyN4LevqIUJibBIWV7HCPRnfpI",
      "authorship_tag": "ABX9TyMLh07NgIK8UNyV7gUspYKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulroynit/Bayesian-vs-Hyperband-Optimization/blob/master/Hyperparameter_Tuning_(Hyperband_vs_Bayesian).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkKRH0HCrMu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create set up for installing kerastuner\n",
        "# installation needed only once\n",
        "import os, sys\n",
        "lib_path = '/content/libraries'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', lib_path)\n",
        "sys.path.insert(0, lib_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAPKMKsYs-hE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install keras-tuner\n",
        "# needs to be run once for permanent installation in colab\n",
        "!pip install --target=$lib_path keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH25TdmopkY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dependencies\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import Hyperband, BayesianOptimization\n",
        "from kerastuner import HyperModel\n",
        "from keras.datasets import boston_housing \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEvEN-Mgq--M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset into train and evaluation data\n",
        "# evaluation data will be split into test and valid data\n",
        "(X_train, y_train), (X_eval, y_eval) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RffHuJsrNQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# query train data\n",
        "print(type(X_train), type(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdmqPNTcrgxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check dims of train and eval data\n",
        "print('dims of train and eval data')\n",
        "print(X_train.shape, X_eval.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJcEIP0CwwXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check train data info\n",
        "print(pd.DataFrame(X_train).info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETaPQbQoRob6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# query train data samples\n",
        "print(pd.DataFrame(X_train).head())\n",
        "print(pd.DataFrame(y_train).head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ZoxV7e14JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split evaluation data into validation and test samples\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_eval, y_eval, test_size = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYFzrCOD83Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data using min-max scaling\n",
        "# train, valid and test predictors are scaled using parameters of train predictors\n",
        "# train and valid target values are scaled using parameters of train target \n",
        "# test target not scaled as it will be used for performance comparison on unseen data\n",
        "# performance comparison to be done after unscaling predictions\n",
        "y_train = y_train.reshape((-1, 1))\n",
        "y_valid = y_valid.reshape((-1, 1))\n",
        "scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "scaler_y.fit(y_train)\n",
        "X_train_array = np.array(scaler_X.transform(X_train))\n",
        "X_valid_array = np.array(scaler_X.transform(X_valid))\n",
        "X_test_array = np.array(scaler_X.transform(X_test))\n",
        "y_train_array = np.array(scaler_y.transform(y_train))\n",
        "y_valid_array = np.array(scaler_y.transform(y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtcs2N-c4dx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check shape of validation data\n",
        "print(X_valid_array.shape, y_valid_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jJ_8SJP9CZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check test data shape\n",
        "# test target should be rank-1 array, i.e., of the form: (N, )\n",
        "print(type(X_test), type(y_test))\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oe5BdZdSXbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model build\n",
        "# define tunable hyperparameters using suitable hyperparameter types\n",
        "# tunable hyperparameters in model: layers, neurons, dropout, learning rate\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units = hp.Int(\"dense_input\", min_value = 32, max_value = 128, step = 32),\n",
        "                                 input_shape = (X_train_array.shape[1],)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(hp.Float(\"drop_input\", min_value = 0, max_value = 0.3, step = 0.1)))\n",
        "  for i in range(hp.Int(\"num_intermediate_layers\", 1, 3)):\n",
        "    model.add(Dense(units = hp.Int(f'dense_{i}', min_value = 32, max_value = 128, step = 32)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(hp.Float(f'drop_{i}', min_value = 0, max_value = 0.3, step = 0.1)))\n",
        "  model.add(Dense(1, activation = \"relu\"))\n",
        "  model.compile(optimizer = Adam(learning_rate = hp.Float('lr', min_value = 0.0001, max_value = 0.01, sampling = \"LOG\", \n",
        "                                                          default = 0.01)), \n",
        "                loss = \"mse\", metrics = [\"mae\"])\n",
        "  return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRhYVte10t37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## set up tensorboard\n",
        "# clear logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "# set up path where logs of tensorboard will be saved\n",
        "# datetime suffix makes the logs unique\n",
        "path = \"logs/hp_tuning/\" + datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "tensorboard = TensorBoard(log_dir = path, histogram_freq = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rPLyCXA0_LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select tuner for hyperparameter tuning (BayesianOptimization (BO) or Hyperband (HB))\n",
        "tuner_choice = \"HB\"\n",
        "# set max_trials (trials) for BO and max_epochs (ep) for HB\n",
        "trials, ep = 10, 50\n",
        "# set batch size\n",
        "bs = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl0T30Ok8DNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up tuner\n",
        "if tuner_choice == \"BO\":\n",
        "  tuner = BayesianOptimization(build_model, objective = \"val_mae\", max_trials = trials, executions_per_trial = 2, \n",
        "                               seed = 2020, project_name = \"bo_tuning\", overwrite = True)\n",
        "else:\n",
        "  tuner = Hyperband(build_model, objective = \"val_mae\", max_epochs = ep, executions_per_trial = 2,\n",
        "                    seed = 2020, project_name = \"hb_tuning\", overwrite = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCk3-LVj7bPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tuner search space summary\n",
        "print(tuner.search_space_summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjG56-Yiy684",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimize hyperparameters\n",
        "# we set up early stopping of tuning if validation loss doesn't improve after 5 epochs  \n",
        "tuner.search(x = X_train_array, y = y_train_array, batch_size = bs, epochs = ep, verbose = 1, validation_data = (X_valid_array, y_valid_array), \n",
        "             callbacks = [EarlyStopping('val_loss', patience = 5), tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nNPqdyZ7GXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tuning summary\n",
        "print(tuner.results_summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xknnyFjTzY2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best hyperparameter values \n",
        "best_hp = pd.DataFrame(tuner.get_best_hyperparameters()[0].values, index = [0])\n",
        "print(best_hp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrsa0tatzkJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "best_model = tuner.get_best_models()[0]\n",
        "print(best_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2tYzOdldyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save best model\n",
        "best_model.save(f'reg_model_{tuner_choice}.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftTB3RyMsFf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best model (if not loaded)\n",
        "best_model = keras.models.load_model('reg_model_HB.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcOd4Ddgz1XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions on test data\n",
        "# predictions are not rank-1 arrays\n",
        "# predictions to be flattened after inverse transformation\n",
        "preds = best_model.predict(x = X_test_array)\n",
        "print(type(preds), preds.shape)\n",
        "print(pd.DataFrame(preds).head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGs_loilC22b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unscale predictions and convert into rank-1 array\n",
        "preds_unscaled = np.array(scaler_y.inverse_transform(preds)).flatten()\n",
        "print(type(preds_unscaled), preds_unscaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOkGjtjGXv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare unscaled predictions and actual values\n",
        "print(pd.DataFrame(preds_unscaled, columns = ['predictions']).head())\n",
        "print(pd.DataFrame(y_test, columns = ['actual_values']).head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qzbmFZf1TPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performance on test data\n",
        "mape = np.mean(np.abs((np.array(y_test) - np.array(preds_unscaled))/np.array(y_test))) * 100\n",
        "mae = np.mean(np.abs(np.array(y_test) - np.array(preds_unscaled)))\n",
        "print(f'mape = {mape} \\n', f'mae = {mae}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_s-WZIkeM9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run tensorboard\n",
        "%tensorboard --logdir logs/hp_tuning"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
